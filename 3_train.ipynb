{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3a. Creating the Dataset\n",
    "\n",
    "The goal of this section is to create a dataset of labeled squares:\n",
    "\n",
    "<p>\n",
    "    <img src=\"images/knight.png\" title=\"Example datapoint\"/>\n",
    "    <br>\n",
    "    <em>Label = 'n'</em>\n",
    "</p>\n",
    "\n",
    "To accomplish this, we have two collections of board images:\n",
    "1. \"boards/train\" - Boards from Chess.com with a variety of piece styles and board colors. Collected from [kaggle.com/koryakinp/chess-positions](https://kaggle.com/koryakinp/chess-positions)\n",
    "2. \"boards/test\" - Boards from Lichess that were collected by myself.\n",
    "\n",
    "Each image has its FEN as the file name. First, we need a way to convert a FEN into an array of 64 labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_fen(fen):\n",
    "    labels = []\n",
    "    fen = fen.split()[0]\n",
    "    fen = fen.split(\".\")[0]\n",
    "    rows = fen.split(\"-\")\n",
    "    for r in rows:\n",
    "        for char in r:\n",
    "            if char.isdigit():\n",
    "                labels += [\"_\"] * int(char)\n",
    "            else:\n",
    "                labels.append(char)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're ready to build our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training set: 15616\n",
      "Size of testing set: 1536\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "from comp_vision import split_image\n",
    "\n",
    "def create_dataset(dir_name):\n",
    "    squares = []\n",
    "    labels = []\n",
    "    # Iterate through board images\n",
    "    for path in glob(dir_name + \"/*.*\"):\n",
    "        board = Image.open(path).convert('L')\n",
    "        new_squares = split_image(board)\n",
    "        if not new_squares:  # Failed to detect board\n",
    "            continue\n",
    "        squares += [np.array(s).reshape(32,32,1) for s in new_squares]\n",
    "        labels += decode_fen(path[len(dir_name)+1:])\n",
    "    return np.array(squares), np.array(labels)\n",
    "\n",
    "\n",
    "train_images, train_labels = create_dataset(\"boards/train\")\n",
    "test_images, test_labels = create_dataset(\"boards/test\")\n",
    "print(\"Size of training set:\", len(train_images))\n",
    "print(\"Size of testing set:\", len(test_images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3b. Building the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to build a convolutional neural network (CNN) that takes in an image of a single square and outputs the piece label.\n",
    "\n",
    "But first, we need to prepare our data. The image grayscale values need to be normalized from 0-255 to 0.0-1.0. Also, the piece labels need to be converted into one-hot encodings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Normalize the pixel values\n",
    "norm_train_images, norm_test_images = train_images/255., test_images/255.\n",
    "\n",
    "# Convert string labels to ints\n",
    "piece_names = ['P','N','B','R','Q','K','p','n','b','r','q','k','_']\n",
    "int_train_labels = np.array([piece_names.index(label) for label in train_labels])\n",
    "int_test_labels = np.array([piece_names.index(label) for label in test_labels])\n",
    "\n",
    "# One-hot encode the labels\n",
    "oh_train_labels = to_categorical(int_train_labels, num_classes=13)\n",
    "oh_test_labels = to_categorical(int_test_labels, num_classes=13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to build the model! It will consist of 3 convolutional layers with max pooling, followed by 2 dense layers for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 30, 30, 16)        160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 15, 15, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 13, 13, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 6, 6, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 4, 4, 32)          9248      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                16416     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 13)                429       \n",
      "=================================================================\n",
      "Total params: 30,893\n",
      "Trainable params: 30,893\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten \n",
    "\n",
    "# Build the model\n",
    "model = Sequential()\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(16, (3, 3), activation='relu', input_shape=(32, 32, 1)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32, activation='tanh'))\n",
    "model.add(Dense(13, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3c. Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "488/488 [==============================] - 3s 6ms/step - loss: 0.2831 - accuracy: 0.9322 - val_loss: 0.1389 - val_accuracy: 0.9798\n",
      "Epoch 2/10\n",
      "488/488 [==============================] - 2s 5ms/step - loss: 0.0562 - accuracy: 0.9876 - val_loss: 0.0665 - val_accuracy: 0.9844\n",
      "Epoch 3/10\n",
      "488/488 [==============================] - 3s 6ms/step - loss: 0.0270 - accuracy: 0.9945 - val_loss: 0.0523 - val_accuracy: 0.9876\n",
      "Epoch 4/10\n",
      "488/488 [==============================] - 3s 5ms/step - loss: 0.0153 - accuracy: 0.9967 - val_loss: 0.0260 - val_accuracy: 0.9902\n",
      "Epoch 5/10\n",
      "488/488 [==============================] - 2s 5ms/step - loss: 0.0085 - accuracy: 0.9985 - val_loss: 0.0293 - val_accuracy: 0.9915\n",
      "Epoch 6/10\n",
      "488/488 [==============================] - 2s 5ms/step - loss: 0.0048 - accuracy: 0.9995 - val_loss: 0.0344 - val_accuracy: 0.9909\n",
      "Epoch 7/10\n",
      "488/488 [==============================] - 2s 5ms/step - loss: 0.0040 - accuracy: 0.9995 - val_loss: 0.0301 - val_accuracy: 0.9876\n",
      "Epoch 8/10\n",
      "488/488 [==============================] - 2s 5ms/step - loss: 0.0025 - accuracy: 0.9998 - val_loss: 0.0217 - val_accuracy: 0.9928\n",
      "Epoch 9/10\n",
      "488/488 [==============================] - 2s 5ms/step - loss: 0.0011 - accuracy: 0.9999 - val_loss: 0.0191 - val_accuracy: 0.9941\n",
      "Epoch 10/10\n",
      "488/488 [==============================] - 3s 5ms/step - loss: 6.8690e-04 - accuracy: 1.0000 - val_loss: 0.0186 - val_accuracy: 0.9922\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(norm_train_images, oh_train_labels, epochs=10,\n",
    "          validation_data=(norm_test_images, oh_test_labels),\n",
    "          verbose=1)\n",
    "\n",
    "model.save(\"model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a model that is ready to use! In \"predict.ipynb\", we'll put it to the test."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
